{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e1b0694c",
   "metadata": {},
   "source": [
    "# Automated Resume Screening Algorithm\n",
    "\n",
    "### Progress: Complete\n",
    "\n",
    "#### by Gingoyon, Arvic Micah B.\n",
    "\n",
    "Specific Progress Notes:\n",
    "#### 2023/07/26 2:58PM\n",
    "\n",
    "Now, I will be integrating the results of the following Jupyter Notebooks: \n",
    "- Soft Skills\n",
    "- Tech Skills\n",
    "- JobExperience\n",
    "\n",
    "The full algorithm will need the following dependencies for their respective purposes:\n",
    "\n",
    "#### Data Manipulation\n",
    "- numpy\n",
    "- pandas\n",
    "\n",
    "#### Text Extraction\n",
    "- re\n",
    "- fitz (install pymupdf)\n",
    "- string\n",
    "- nltk (install nltk)\n",
    "\n",
    "#### AI\n",
    "- pickle\n",
    "\n",
    "#### Synonym Lookup\n",
    "- wordhoard (install wordhoard)\n",
    "\n",
    "#### Date Computation\n",
    "- datetime\n",
    "\n",
    "The following models need to be available:\n",
    "- JobIdentifier\n",
    "- DateIdentifier\n",
    "- IndustryClassifier\n",
    "- SoftSkillIdentifier\n",
    "- SoftSkillClusters\n",
    "\n",
    "The following datasets need to be available:\n",
    "- SoftSkills\n",
    "- TechnologySkills\n",
    "- HardSkills"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a74964e9",
   "metadata": {},
   "source": [
    "# Models and Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "5ae457d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#AI Models\n",
    "ji = pickle.load(open('JobIdentifier.pkl', 'rb')) #JobIdentifier\n",
    "di = pickle.load(open('Dateidentifier.pkl', 'rb')) #DateIdentifier\n",
    "ic = pickle.load(open('IndustryClassifier.pkl', 'rb')) #IndustryClassifier\n",
    "si = pickle.load(open('SoftSkillIdentifier.pkl', 'rb')) #SoftSkillIdentifier\n",
    "sc = pickle.load(open('SoftSkillClusters.pkl','rb')) #SoftSkillClusters\n",
    "\n",
    "#Datasets\n",
    "softskills = pd.read_csv('SoftSkills.csv')\n",
    "str_tolist(softskills) ## Converts the string-type lists when loading the CSV back into lists.\n",
    "techskills = pd.read_csv('TechnologySkills.csv')\n",
    "hardskills = pd.read_csv('HardSkills.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52c1bfb8",
   "metadata": {},
   "source": [
    "# Helper Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cce9195",
   "metadata": {},
   "source": [
    "#### str_tolist(DataFrame):\n",
    "This can only be used for a DataFrame that is composed of a lists of words. This will separate each word by commas (happens when you converts a DataFrame with lists into a CSV file), and substitute each index for that column with a list of the split words instead of the original string that is read from the CSV.\n",
    "\n",
    "*Made specifically during development of Soft Skill Extraction. For Soft Skills dataset only*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f89239c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def str_tolist(df):\n",
    "    for j in range(0, df.shape[0]):\n",
    "        wlist = []\n",
    "        for i in df.iloc[j,0].split(','):\n",
    "            wlist.append(i.strip(\"[],.' \"))\n",
    "\n",
    "        df.iloc[j,0] = wlist"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f1cce26",
   "metadata": {},
   "source": [
    "# Main Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "829d1037",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extractApplicantData(filepath):\n",
    "    doc = fitz.open(filepath)\n",
    "    text = \"\"\n",
    "    for page in doc:\n",
    "       text+=page.get_text()\n",
    "    \n",
    "    text = text.replace('\\n', ' ')\n",
    "    text = text.translate(str.maketrans('', '', string.punctuation))\n",
    "    text = text.replace('\\n\\r-', ' ')\n",
    "    \n",
    "    return text  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56b5d6f6",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9f1a63d",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fefef690",
   "metadata": {},
   "source": [
    "# Job Experience"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e20a844a",
   "metadata": {},
   "source": [
    "#### extractJobExperience(text, JobIdentifier, DateIdentifier, IndustryClassifier):\n",
    "\n",
    "This will extract the "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "ba2f56d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extractJobExperience(text, ji, di, ic):\n",
    "    \n",
    "    #Text Manipulation\n",
    "    text = text.lower() #Because this function was made to process text in lowervase.\n",
    "    \n",
    "    ##Extracting predicted job titles using trigrams\n",
    "    txt_splt = text.split()\n",
    "    trigrams = []\n",
    "    for i in range (0,len(txt_splt)-3):\n",
    "        trigrams.append((f'{txt_splt[i]} {txt_splt[i+1]} {txt_splt[i+2]}'))\n",
    "\n",
    "    pred = ji.predict(trigrams)\n",
    "    titles = []\n",
    "\n",
    "    for i in range(0,len(trigrams)):\n",
    "        if pred[i] == 1:\n",
    "            titles.append(trigrams[i])\n",
    "                    \n",
    "    \n",
    "    ##Classifying them to industries\n",
    "    preds = ic.predict(titles)\n",
    "    preds = pd.DataFrame(preds)\n",
    "    preds.columns = ['Labels']\n",
    "    preds['Counts'] = 1\n",
    "    \n",
    "    industries = pd.DataFrame(preds.groupby('Labels').count().sort_values('Counts', ascending = False).reset_index())\n",
    "    \n",
    "    ##Identifying dates within the text\n",
    "    grams = text.split()\n",
    "    pred = di.predict(grams)\n",
    "\n",
    "    dates = []\n",
    "    for i in range(0, len(grams)):\n",
    "        if pred[i] == 1:\n",
    "            if grams[i] == 'present' or grams[i] == 'Present' or grams[i] == 'current' or grams[i] == 'Current':\n",
    "                today = datetime.date.today()\n",
    "                year = today.strftime(\"%Y\")\n",
    "            else:\n",
    "                found = re.findall('\\d{4}', grams[i])\n",
    "                if not found:\n",
    "                    dates.append(0)\n",
    "                else: \n",
    "                    year = found[0]\n",
    "\n",
    "            dates.append(int(year))\n",
    "    \n",
    "    ##Computing total years from gathered dates\n",
    "    years = 0\n",
    "    for i in range(0,len(dates)-1):\n",
    "        if dates[i] < dates[i+1] and dates[i] != 0:\n",
    "            years+=(dates[i+1]-dates[i])\n",
    "    \n",
    "    ##Outputting results\n",
    "    output = []\n",
    "    top = []\n",
    "    for j in range(0, 2):\n",
    "        labels = industries['Labels']\n",
    "        top.append(labels[j])\n",
    "    \n",
    "    if years >= 1:\n",
    "        output.append((top, f'{years} year/s'))\n",
    "    else:\n",
    "        output.append((top, 'Less than a year experience'))\n",
    "        \n",
    "    return output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfeafa6a",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "509a69ed",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1aee028f",
   "metadata": {},
   "source": [
    "# Soft Skills"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5171b8ce",
   "metadata": {},
   "source": [
    "#### extractSoftSkills(text, SoftSkillCorpus, SoftSkillIdentifier, SoftSkillClusters):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "6186216e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extractSoftSkills(text, scorpus, si, sc):\n",
    "    \n",
    "    #Text Manipulation\n",
    "    text = text.lower() #Because this function was made to process text in lowervase.\n",
    "    \n",
    "    ##Extract soft skills from text\n",
    "    slist = []\n",
    "    grams = []\n",
    "    spltxt = text.split()\n",
    "    stop_words = ['i', 'me', 'skills', 'ability','skill', 'abilities','my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', 'her', 'hers', 'herself', 'it', 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', 'should', 'now']\n",
    "    for i in range(0,len(spltxt)-1):\n",
    "        if spltxt[i] not in stop_words not in stop_words:\n",
    "            word = re.sub(\"[^A-Z]\", \"\", spltxt[i].strip(\",.;!?\"),0,re.IGNORECASE)\n",
    "            grams.append(word)\n",
    "    \n",
    "    if not grams:\n",
    "        slist.append(' ')\n",
    "    else:\n",
    "        pred = si.predict(grams)\n",
    "        for i in range(0, len(grams)):\n",
    "            if pred[i] == 1:\n",
    "                if grams[i] not in slist:\n",
    "                    slist.append(grams[i])\n",
    "    \n",
    "    \n",
    "    ##Getting Synonyms from Corpus\n",
    "    skills = []\n",
    "    skill = []\n",
    "    for s in slist:\n",
    "        for i in range(0, scorpus.shape[0]):\n",
    "            if s == scorpus.iloc[i,0][0]:\n",
    "                skill = scorpus.iloc[i,0]\n",
    "        if not skill:\n",
    "            for i in range(0, scorpus.shape[0]):\n",
    "                for j in scorpus.iloc[i,0]:\n",
    "                    if s == j:\n",
    "                        skill = scorpus.iloc[i,0]\n",
    "    \n",
    "        skills.append(skill)\n",
    "        \n",
    "    ##Stemming\n",
    "    sno = nltk.stem.SnowballStemmer('english')\n",
    "    stemmed = []\n",
    "    for i in range(0,len(skills)):\n",
    "        stems = ''\n",
    "        for j in skills[i]:\n",
    "            if sno.stem(j) not in stems:\n",
    "                stems += ' ' + sno.stem(j)\n",
    "        if stems not in stemmed:\n",
    "            stemmed.append(stems)\n",
    "    \n",
    "    ##Predicting with Cluster model\n",
    "    prediction = sc.predict(stemmed)\n",
    "    \n",
    "    ##Interpreting the results of the prediction\n",
    "    output = []\n",
    "    for i in prediction:\n",
    "        if i == 0: \n",
    "            if 'Communication/Teamwork' not in output: output.append('Communication/Teamwork')\n",
    "        elif i == 1: \n",
    "            if 'Decision-Making' not in output: output.append('Decision-Making')\n",
    "        elif i == 2: \n",
    "            if 'Creativity/Innovation' not in output: output.append('Creativity/Innovation')\n",
    "        elif i == 3: \n",
    "            if 'Manners/Courtesy' not in output: output.append('Manners/Courtesy')\n",
    "        elif i == 4: \n",
    "            if 'Adaptability/Versatility' not in output: output.append('Adaptability/Versatility')\n",
    "        elif i == 5: \n",
    "            if 'Confidence/Optimism' not in output: output.append('Confidence/Optimism')\n",
    "        elif i == 6: \n",
    "            if 'Efficiency/Well-Organized' not in output: output.append('Efficiency/Well-Organized')\n",
    "        elif i == 7: \n",
    "            if 'Leadership/Accountability' not in output: output.append('Leadership/Accountability')\n",
    "        elif i == 8: \n",
    "            if 'Control/Discipline' not in output: output.append('Control/Discipline')\n",
    "    \n",
    "    return output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bf0accc",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d67bb6e",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed9d2c5f",
   "metadata": {},
   "source": [
    "# Hard Skills and Tech Skills"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffb18a8f",
   "metadata": {},
   "source": [
    "#### extractTechSkills(text, HardSkills, TechSkills, SoftSkillIdentifier):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "45fa1c55",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extractTechSkills(text, hs, ts, si):\n",
    "    \n",
    "    hskills = []\n",
    "    tskills = []\n",
    "    hcount = 0\n",
    "    tcount = 0\n",
    "    \n",
    "    if hs.shape[0] > ts.shape[0]:\n",
    "        ##Extracting Hard Skills\n",
    "        for i in range(0,hs.shape[0]):\n",
    "            if hs.iloc[i,0] in text and hs.iloc[i,0] and hs.iloc[i,0] not in (ts.iloc[:,0].tolist()):\n",
    "                if len(hs.iloc[i,0].split())>1:\n",
    "                    if not hskills:\n",
    "                        hskills.append(hs.iloc[i,0])\n",
    "                        hcount += 1\n",
    "                    else:\n",
    "                        if hskills[hcount-1] in hs.iloc[i,0]:\n",
    "                            hskills[hcount-1] = hs.iloc[i,0]\n",
    "                        elif hs.iloc[i,0] in hskills[hcount-1]:\n",
    "                            continue\n",
    "                        else:\n",
    "                            hskills.append(hs.iloc[i,0])\n",
    "                            hcount+=1\n",
    "            \n",
    "            if i < ts.shape[0]:\n",
    "                if ts.iloc[i,0] in text and ts.iloc[i,0] not in ['R', 'C', 'J', 'SKILL', 'Dig']: \n",
    "                #I added the awkward list of tech skills here because they almost always pop up even though they're not actually there. \n",
    "                #C++ can be detected but C will be difficult. This may be the reason why LinkedIn also cannot input C as a skill.\n",
    "                    if not tskills:\n",
    "                        tskills.append(ts.iloc[i,0])\n",
    "                        tcount += 1\n",
    "                    else:\n",
    "                        if tskills[tcount-1] in ts.iloc[i,0]:\n",
    "                            tskills[tcount-1] = ts.iloc[i,0]\n",
    "                        elif ts.iloc[i,0] in tskills[tcount-1]:\n",
    "                            continue\n",
    "                        else:\n",
    "                            tskills.append(ts.iloc[i,0])\n",
    "                            tcount+=1\n",
    "        \n",
    "    else:\n",
    "        ##Extracting Tech Skills\n",
    "        for i in range(0,ts.shape[0]):\n",
    "            if ts.iloc[i,0] in text and ts.iloc[i,0] not in ['R', 'C', 'J', 'SKILL', 'Dig']: \n",
    "                #I added the awkward list of tech skills here because they almost always pop up even though they're not actually there. \n",
    "                #C++ can be detected but C will be difficult. This may be the reason why LinkedIn also cannot input C as a skill.\n",
    "                if not tskills:\n",
    "                    tskills.append(ts.iloc[i,0])\n",
    "                    tcount += 1\n",
    "                else:\n",
    "                    if tskills[tcount-1] in ts.iloc[i,0]:\n",
    "                        tskills[tcount-1] = ts.iloc[i,0]\n",
    "                    elif ts.iloc[i,0] in tskills[tcount-1]:\n",
    "                        continue\n",
    "                    else:\n",
    "                        tskills.append(ts.iloc[i,0])\n",
    "                        tcount+=1\n",
    "            if i < hs.shape[0]:\n",
    "                if hs.iloc[i,0] in text and hs.iloc[i,0] and hs.iloc[i,0] not in (ts.iloc[:,0].tolist()):\n",
    "                    if len(hs.iloc[i,0].split())>1:\n",
    "                        if not hskills:\n",
    "                            hskills.append(hs.iloc[i,0])\n",
    "                            hcount += 1\n",
    "                        else:\n",
    "                            if hskills[hcount-1] in hs.iloc[i,0]:\n",
    "                                hskills[hcount-1] = hs.iloc[i,0]\n",
    "                            elif hs.iloc[i,0] in hskills[hcount-1]:\n",
    "                                continue\n",
    "                            else:\n",
    "                                hskills.append(hs.iloc[i,0])\n",
    "                                hcount+=1\n",
    "                                \n",
    "    ##Removing Soft Skills detected.\n",
    "    if hskills:\n",
    "        hpred = si.predict(hskills)\n",
    "    if tskills:\n",
    "        tpred = si.predict(tskills)\n",
    "    outh = []\n",
    "    outt = []\n",
    "        \n",
    "    if len(hskills) > len(tskills):\n",
    "        for i in range(0,len(hskills)):\n",
    "            if hpred[i] == 0:\n",
    "                outh.append(hskills[i])\n",
    "            \n",
    "            if tskills:\n",
    "                if i < len(tskills):\n",
    "                    if tpred[i] == 0:\n",
    "                        outt.append(tskills[i])\n",
    "    else:\n",
    "        for i in range(0,len(tskills)):\n",
    "            if tpred[i] == 0:\n",
    "                outt.append(tskills[i])\n",
    "            \n",
    "            if hskills:\n",
    "                if i < len(hskills):\n",
    "                    if hpred[i] == 0:\n",
    "                        outh.append(hskills[i])\n",
    "                        \n",
    "    if outh and outt:\n",
    "        return outh, outt\n",
    "    elif outh and not outt:\n",
    "        return outh, 'No Specific Software Skills.'\n",
    "    elif not outh and outt:\n",
    "        return 'No Specific Hard Skills.', outt\n",
    "    else:\n",
    "        return 'No Specific Hard Skills.', 'No Specific Software Skills.'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42c916db",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec4787df",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cd6375a",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cfc2a66",
   "metadata": {},
   "source": [
    "# Testing the Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "6a17d3e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import fitz\n",
    "import string\n",
    "import nltk\n",
    "import pickle\n",
    "from wordhoard import Synonyms\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "7cf1c7fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "test1 = extractApplicantData('resume7.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "a3a15085",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(['CUSTOMER SERVICE', 'ACCOUNTING & FINANCE'], 'Less than a year experience')]"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extractJobExperience(test1, ji, di, ic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "170cfe33",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Efficiency/Well-Organized',\n",
       " 'Creativity/Innovation',\n",
       " 'Confidence/Optimism',\n",
       " 'Adaptability/Versatility',\n",
       " 'Communication/Teamwork',\n",
       " 'Leadership/Accountability']"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extractSoftSkills(test1, softskills, si, sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "8e1bb089",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['Customer Service'],\n",
       " ['Cin7',\n",
       "  'Mi9 Merchant',\n",
       "  'Netsuite',\n",
       "  'ProsperWorks CRM',\n",
       "  'Freshsales',\n",
       "  'Pipedrive'])"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extractTechSkills(test1, hardskills, techskills, si)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78357c0f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
